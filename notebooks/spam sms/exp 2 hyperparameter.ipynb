{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6de117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training CNN | embed=64, filters=64, kernel=3, dropout=0.3, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "F1 Score: 0.9589\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=3, dropout=0.3, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "F1 Score: 0.9488\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=3, dropout=0.3, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9225\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=3, dropout=0.3, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "F1 Score: 0.9078\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=3, dropout=0.5, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "F1 Score: 0.9589\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=3, dropout=0.5, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "F1 Score: 0.9586\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=3, dropout=0.5, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "F1 Score: 0.9306\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=3, dropout=0.5, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "F1 Score: 0.8731\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=5, dropout=0.3, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "F1 Score: 0.9556\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=5, dropout=0.3, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9589\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=5, dropout=0.3, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
      "F1 Score: 0.9655\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=5, dropout=0.3, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "F1 Score: 0.9437\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=5, dropout=0.5, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "F1 Score: 0.9619\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=5, dropout=0.5, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "F1 Score: 0.9689\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=5, dropout=0.5, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "F1 Score: 0.9514\n",
      "\n",
      "Training CNN | embed=64, filters=64, kernel=5, dropout=0.5, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "F1 Score: 0.9319\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=3, dropout=0.3, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9622\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=3, dropout=0.3, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9550\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=3, dropout=0.3, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "F1 Score: 0.9514\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=3, dropout=0.3, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "F1 Score: 0.9155\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=3, dropout=0.5, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9586\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=3, dropout=0.5, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "F1 Score: 0.9655\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=3, dropout=0.5, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9384\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=3, dropout=0.5, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9333\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=5, dropout=0.3, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "F1 Score: 0.9553\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=5, dropout=0.3, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "F1 Score: 0.9619\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=5, dropout=0.3, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "F1 Score: 0.9617\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=5, dropout=0.3, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9544\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=5, dropout=0.5, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "F1 Score: 0.9583\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=5, dropout=0.5, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "F1 Score: 0.9589\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=5, dropout=0.5, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "F1 Score: 0.9619\n",
      "\n",
      "Training CNN | embed=64, filters=128, kernel=5, dropout=0.5, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9510\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=3, dropout=0.3, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "F1 Score: 0.9463\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=3, dropout=0.3, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "F1 Score: 0.9556\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=3, dropout=0.3, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
      "F1 Score: 0.9416\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=3, dropout=0.3, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
      "F1 Score: 0.9404\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=3, dropout=0.5, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "F1 Score: 0.9517\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=3, dropout=0.5, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "F1 Score: 0.9586\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=3, dropout=0.5, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "F1 Score: 0.9420\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=3, dropout=0.5, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step\n",
      "F1 Score: 0.8750\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=5, dropout=0.3, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "F1 Score: 0.9396\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=5, dropout=0.3, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "F1 Score: 0.9524\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=5, dropout=0.3, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "F1 Score: 0.9510\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=5, dropout=0.3, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "F1 Score: 0.9474\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=5, dropout=0.5, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "F1 Score: 0.9521\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=5, dropout=0.5, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "F1 Score: 0.9653\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=5, dropout=0.5, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "F1 Score: 0.9583\n",
      "\n",
      "Training CNN | embed=128, filters=64, kernel=5, dropout=0.5, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step\n",
      "F1 Score: 0.9404\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=3, dropout=0.3, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "F1 Score: 0.9589\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=3, dropout=0.3, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "F1 Score: 0.9658\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=3, dropout=0.3, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "F1 Score: 0.9619\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=3, dropout=0.3, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step\n",
      "F1 Score: 0.9547\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=3, dropout=0.5, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "F1 Score: 0.9622\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=3, dropout=0.5, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "F1 Score: 0.9622\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=3, dropout=0.5, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "F1 Score: 0.9619\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=3, dropout=0.5, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step\n",
      "F1 Score: 0.9481\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=5, dropout=0.3, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step\n",
      "F1 Score: 0.9498\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=5, dropout=0.3, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "F1 Score: 0.9583\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=5, dropout=0.3, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "F1 Score: 0.9586\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=5, dropout=0.3, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step\n",
      "F1 Score: 0.9547\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=5, dropout=0.5, lr=0.001, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "F1 Score: 0.9586\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=5, dropout=0.5, lr=0.001, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "F1 Score: 0.9586\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=5, dropout=0.5, lr=0.0003, batch=32\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "F1 Score: 0.9655\n",
      "\n",
      "Training CNN | embed=128, filters=128, kernel=5, dropout=0.5, lr=0.0003, batch=64\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step\n",
      "F1 Score: 0.9477\n",
      "\n",
      "ğŸ”¥ Best CNN Model\n",
      "Best F1 Score: 0.9689\n",
      "Best Hyperparameters:\n",
      "embed_dim: 64\n",
      "filters: 64\n",
      "kernel_size: 5\n",
      "dropout_rate: 0.5\n",
      "learning_rate: 0.001\n",
      "batch_size: 64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load data\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
    "df = df[[\"v1\", \"v2\"]]\n",
    "df = df.rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"label\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"],\n",
    "    df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Tokenization\n",
    "# ----------------------------\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_pad = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_train),\n",
    "    maxlen=MAX_LEN,\n",
    "    padding=\"post\"\n",
    ")\n",
    "\n",
    "X_test_pad = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_test),\n",
    "    maxlen=MAX_LEN,\n",
    "    padding=\"post\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. CNN model builder\n",
    "# ----------------------------\n",
    "def build_cnn_model(\n",
    "    embed_dim=128,\n",
    "    filters=128,\n",
    "    kernel_size=5,\n",
    "    dropout_rate=0.5,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    model = Sequential([\n",
    "        Embedding(VOCAB_SIZE, embed_dim),\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation=\"relu\"),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# ----------------------------\n",
    "# 4. Hyperparameter grid\n",
    "# ----------------------------\n",
    "param_grid = {\n",
    "    \"embed_dim\": [64, 128],\n",
    "    \"filters\": [64, 128],\n",
    "    \"kernel_size\": [3, 5],\n",
    "    \"dropout_rate\": [0.3, 0.5],\n",
    "    \"learning_rate\": [1e-3, 3e-4],\n",
    "    \"batch_size\": [32, 64]\n",
    "}\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Grid search\n",
    "# ----------------------------\n",
    "best_f1 = 0\n",
    "best_params = None\n",
    "\n",
    "for embed_dim in param_grid[\"embed_dim\"]:\n",
    "    for filters in param_grid[\"filters\"]:\n",
    "        for kernel_size in param_grid[\"kernel_size\"]:\n",
    "            for dropout_rate in param_grid[\"dropout_rate\"]:\n",
    "                for lr in param_grid[\"learning_rate\"]:\n",
    "                    for batch_size in param_grid[\"batch_size\"]:\n",
    "\n",
    "                        print(\n",
    "                            f\"Training CNN | embed={embed_dim}, filters={filters}, \"\n",
    "                            f\"kernel={kernel_size}, dropout={dropout_rate}, \"\n",
    "                            f\"lr={lr}, batch={batch_size}\"\n",
    "                        )\n",
    "\n",
    "                        model = build_cnn_model(\n",
    "                            embed_dim=embed_dim,\n",
    "                            filters=filters,\n",
    "                            kernel_size=kernel_size,\n",
    "                            dropout_rate=dropout_rate,\n",
    "                            learning_rate=lr\n",
    "                        )\n",
    "\n",
    "                        model.fit(\n",
    "                            X_train_pad,\n",
    "                            y_train,\n",
    "                            epochs=5,\n",
    "                            batch_size=batch_size,\n",
    "                            validation_split=0.1,\n",
    "                            verbose=0\n",
    "                        )\n",
    "\n",
    "                        y_pred = (model.predict(X_test_pad) > 0.5).astype(int)\n",
    "                        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "                        print(f\"F1 Score: {f1:.4f}\\n\")\n",
    "\n",
    "                        if f1 > best_f1:\n",
    "                            best_f1 = f1\n",
    "                            best_params = {\n",
    "                                \"embed_dim\": embed_dim,\n",
    "                                \"filters\": filters,\n",
    "                                \"kernel_size\": kernel_size,\n",
    "                                \"dropout_rate\": dropout_rate,\n",
    "                                \"learning_rate\": lr,\n",
    "                                \"batch_size\": batch_size\n",
    "                            }\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Best result\n",
    "# ----------------------------\n",
    "print(\"ğŸ”¥ Best CNN Model\")\n",
    "print(f\"Best F1 Score: {best_f1:.4f}\")\n",
    "print(\"Best Hyperparameters:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"{k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed7cf297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Threshold: 40%\n",
      "Accuracy : 0.9749\n",
      "Precision: 0.9060\n",
      "Recall   : 0.9060\n",
      "F1-score : 0.9060\n",
      "Threshold: 45%\n",
      "Accuracy : 0.9749\n",
      "Precision: 0.9060\n",
      "Recall   : 0.9060\n",
      "F1-score : 0.9060\n",
      "Threshold: 50%\n",
      "Accuracy : 0.9767\n",
      "Precision: 0.9184\n",
      "Recall   : 0.9060\n",
      "F1-score : 0.9122\n",
      "Threshold: 55%\n",
      "Accuracy : 0.9758\n",
      "Precision: 0.9178\n",
      "Recall   : 0.8993\n",
      "F1-score : 0.9085\n",
      "Threshold: 60%\n",
      "Accuracy : 0.9767\n",
      "Precision: 0.9301\n",
      "Recall   : 0.8926\n",
      "F1-score : 0.9110\n",
      "Threshold: 65%\n",
      "Accuracy : 0.9767\n",
      "Precision: 0.9301\n",
      "Recall   : 0.8926\n",
      "F1-score : 0.9110\n",
      "Threshold: 70%\n",
      "Accuracy : 0.9767\n",
      "Precision: 0.9301\n",
      "Recall   : 0.8926\n",
      "F1-score : 0.9110\n",
      "Threshold: 75%\n",
      "Accuracy : 0.9794\n",
      "Precision: 0.9500\n",
      "Recall   : 0.8926\n",
      "F1-score : 0.9204\n",
      "Threshold: 80%\n",
      "Accuracy : 0.9803\n",
      "Precision: 0.9568\n",
      "Recall   : 0.8926\n",
      "F1-score : 0.9236\n",
      "Threshold: 85%\n",
      "Accuracy : 0.9812\n",
      "Precision: 0.9638\n",
      "Recall   : 0.8926\n",
      "F1-score : 0.9268\n",
      "Threshold: 90%\n",
      "Accuracy : 0.9803\n",
      "Precision: 0.9635\n",
      "Recall   : 0.8859\n",
      "F1-score : 0.9231\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# 6. Evaluate the model\n",
    "# ----------------------------\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "th= [ 40, 45, 50, 55, 60, 65, 70, 75, 80, 85,90]\n",
    "for th in th:\n",
    "    y_pred = (y_pred_prob > th/100).astype(int).ravel()\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print(f\"Threshold: {th}%\")\n",
    "    print(f\"Accuracy : {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall   : {recall:.4f}\")\n",
    "    print(f\"F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "453b36d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_66\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_66\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_pooling1d_66         â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ ?                      â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               â”‚ ?                      â”‚   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ embedding_66 (\u001b[38;5;33mEmbedding\u001b[0m)        â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_66 (\u001b[38;5;33mConv1D\u001b[0m)              â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_pooling1d_66         â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_66 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ ?                      â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_132 (\u001b[38;5;33mDense\u001b[0m)               â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_133 (\u001b[38;5;33mDense\u001b[0m)               â”‚ ?                      â”‚   \u001b[38;5;34m0\u001b[0m (unbuilt) â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 72ms/step - accuracy: 0.8611 - loss: 0.4010 - val_accuracy: 0.8453 - val_loss: 0.3073\n",
      "Epoch 2/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.9459 - loss: 0.1328 - val_accuracy: 0.9843 - val_loss: 0.0712\n",
      "Epoch 3/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 57ms/step - accuracy: 0.9920 - loss: 0.0282 - val_accuracy: 0.9843 - val_loss: 0.0526\n",
      "Epoch 4/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9988 - loss: 0.0075 - val_accuracy: 0.9865 - val_loss: 0.0446\n",
      "Epoch 5/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9990 - loss: 0.0037 - val_accuracy: 0.9865 - val_loss: 0.0456\n",
      "Epoch 6/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9995 - loss: 0.0024 - val_accuracy: 0.9843 - val_loss: 0.0464\n",
      "Epoch 7/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 56ms/step - accuracy: 1.0000 - loss: 0.0010 - val_accuracy: 0.9888 - val_loss: 0.0477\n",
      "Epoch 8/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 1.0000 - loss: 5.0068e-04 - val_accuracy: 0.9910 - val_loss: 0.0487\n",
      "Epoch 9/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 1.0000 - loss: 4.2138e-04 - val_accuracy: 0.9888 - val_loss: 0.0490\n",
      "Epoch 10/10\n",
      "\u001b[1m63/63\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 3.2173e-04 - val_accuracy: 0.9910 - val_loss: 0.0499\n",
      "\u001b[1m35/35\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step\n",
      "Accuracy : 0.9892\n",
      "Precision: 0.9858\n",
      "Recall   : 0.9329\n",
      "F1-score : 0.9586\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load data\n",
    "# ----------------------------\n",
    "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
    "df = df[[\"v1\", \"v2\"]]\n",
    "df = df.rename(columns={\"v1\": \"label\", \"v2\": \"text\"})\n",
    "\n",
    "le = LabelEncoder()\n",
    "df[\"label\"] = le.fit_transform(df[\"label\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[\"text\"],\n",
    "    df[\"label\"],\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=df[\"label\"]\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Tokenization\n",
    "# ----------------------------\n",
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_pad = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_train),\n",
    "    maxlen=MAX_LEN,\n",
    "    padding=\"post\"\n",
    ")\n",
    "\n",
    "X_test_pad = pad_sequences(\n",
    "    tokenizer.texts_to_sequences(X_test),\n",
    "    maxlen=MAX_LEN,\n",
    "    padding=\"post\"\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 3. CNN model builder\n",
    "# ----------------------------\n",
    "def build_cnn_model(\n",
    "    embed_dim=128,\n",
    "    filters=128,\n",
    "    kernel_size=5,\n",
    "    dropout_rate=0.5,\n",
    "    learning_rate=1e-3\n",
    "):\n",
    "    model = Sequential([\n",
    "        Embedding(VOCAB_SIZE, embed_dim),\n",
    "        Conv1D(filters=filters, kernel_size=kernel_size, activation=\"relu\"),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "# ----------------------------\n",
    "# 4. Build model with best hyperparameters\n",
    "# ----------------------------\n",
    "best_params = {\n",
    "    \"embed_dim\": 128,\n",
    "    \"filters\": 128,\n",
    "    \"kernel_size\": 3,\n",
    "    \"dropout_rate\": 0.5,\n",
    "    \"learning_rate\": 0.001\n",
    "}\n",
    "\n",
    "model = build_cnn_model(\n",
    "    embed_dim=best_params[\"embed_dim\"],\n",
    "    filters=best_params[\"filters\"],\n",
    "    kernel_size=best_params[\"kernel_size\"],\n",
    "    dropout_rate=best_params[\"dropout_rate\"],\n",
    "    learning_rate=best_params[\"learning_rate\"]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Train the model\n",
    "# ----------------------------\n",
    "history = model.fit(\n",
    "    X_train_pad,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Evaluate the model\n",
    "# ----------------------------\n",
    "y_pred_prob = model.predict(X_test_pad)\n",
    "y_pred = (y_pred_prob > 0.7).astype(int).ravel()\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2250ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution:\n",
      "label\n",
      "0    4825\n",
      "1     747\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution in percentage:\n",
      "label\n",
      "0    86.593683\n",
      "1    13.406317\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['label'].value_counts()\n",
    "print(\"Class distribution:\")\n",
    "print(class_counts)\n",
    "\n",
    "class_percent = df['label'].value_counts(normalize=True) * 100\n",
    "print(\"\\nClass distribution in percentage:\")\n",
    "print(class_percent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
